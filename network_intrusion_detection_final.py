# -*- coding: utf-8 -*-
"""Network-Intrusion-Detection-final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PtCz159VhDnSpuvYYKtvQmM8bILLfOp_
"""

import pandas as pd
df = pd.read_csv("/content/sample_data/UNR-IDD.csv")

df.head()

df['Label'].unique()

df['Binary Label'].unique()

df['Label'].value_counts()

# Drop all duplicates in the data
df.drop_duplicates(inplace=True)

# Check if there is a null in the data
df.isnull().sum()

import seaborn as sns
# Display "Binary Label" column
sns.countplot(data=df, x="Binary Label", palette="husl")

# Display "Label" column
sns.countplot(data=df, x="Label", palette="husl")

#Split Attack and Normal from the dataframe
data_attack = df[df['Binary Label'] == 'Attack']
data_normal = df[df['Binary Label'] == 'Normal']

import matplotlib.pyplot as plt
# Display attack distribution in pie chart
data_attack['Label'].value_counts().plot(kind='pie', autopct='%1.2f%%')
plt.title("Attack Distribution")
plt.show()

data_tcpsyn_attack = df[df['Label'] == 'TCP-SYN']

data_tcpsyn_attack.head()

data_tcpsyn_attack.columns

selected_columns = [
    'Received Packets', 'Delta Received Packets', 'Received Bytes', 'Delta Received Bytes',
    'Sent Packets', 'Delta Sent Packets', 'Packets Rx Dropped', 'Delta Packets Rx Dropped',
    'Port alive Duration (S)', 'Delta Port alive Duration (S)', 'Packets Rx Errors', 'Delta Packets Rx Errors',
    'Total Load/Rate', 'Unknown Load/Rate', 'Active Flow Entries'
]
data_tcpsyn_attack_selected = data_tcpsyn_attack[selected_columns]
data_tcpsyn_attack_selected.head()

data_tcpsyn_attack_selected.count()

selected_columns = [
    'Received Packets', 'Delta Received Packets', 'Received Bytes', 'Delta Received Bytes',
    'Sent Packets', 'Delta Sent Packets', 'Packets Rx Dropped', 'Delta Packets Rx Dropped',
    'Port alive Duration (S)', 'Delta Port alive Duration (S)', 'Packets Rx Errors', 'Delta Packets Rx Errors',
    'Total Load/Rate', 'Unknown Load/Rate', 'Active Flow Entries'
]
data_normal_selected = data_normal[selected_columns]
data_normal_selected.head()

import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# Data Preparation
# Merge TCP-SYN attack data and normal data into one data frame
data_tcpsyn_attack_selected['Binary Label'] = 1  # labeled Attack as 1
data_normal_selected['Binary Label'] = 0         # labeled Normal as 0
data_combined = pd.concat([data_tcpsyn_attack_selected, data_normal_selected])

# Separate features and labels
X = data_combined.drop(columns=['Binary Label']).values  # feature data
y = data_combined['Binary Label'].values                 # label data

# Data standardization (scaling)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split into training and test data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# Convert to tensor
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

# Weight calculation
# This is due to the difference in the number of TCP-SYN data (9081) and the number of Normal data (3773).
# When learning the model, the weights are set differently for each class to compensate for the data imbalance.
# Since there are 3773 Normal data and 9081 TCP-SYN Attack data, weights that are inversely proportional to each are calculated.
class_counts = np.bincount(y_train.astype(int))
class_weights = [len(y_train) / (len(np.unique(y_train)) * count) for count in class_counts]
class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)

#1. Define Transformer architecture
class TransformerModel(nn.Module):
    def __init__(self, input_dim, num_heads, num_layers, hidden_dim):
        super(TransformerModel, self).__init__()
        self.embedding = nn.Linear(input_dim, hidden_dim)
        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.fc = nn.Linear(hidden_dim, 1)  # Output layer for binary classification

    def forward(self, x):
        x = self.embedding(x).unsqueeze(1)  # Dimension expansion after applying embedding layer
        x = self.transformer_encoder(x)  # Transformer encoder
        x = x.mean(dim=1)  # Pooling
        x = self.fc(x)
        return x

# Create a model instance
input_dim = X_train_tensor.shape[1]  # Number of features in the input data
model = TransformerModel(input_dim=input_dim, num_heads=4, num_layers=2, hidden_dim=64)  # Adjust parameters as needed

# Train setting
criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1]) # Applying weights to TCP-SYN attacks
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 3. Train
epochs = 20
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    output = model(X_train_tensor)
    loss = criterion(output.view(-1), y_train_tensor)
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}")

# 4. Test
model.eval()
with torch.no_grad():
    test_output = model(X_test_tensor)
    predictions = torch.sigmoid(test_output).view(-1).numpy()
    predictions = (predictions > 0.5).astype(int)  # If it is greater than 0.5, label it as 1
    accuracy = (predictions == y_test).mean()
    print(f"Test Accuracy: {accuracy}")